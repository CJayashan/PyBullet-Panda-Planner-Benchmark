"""benchmark_runner.py
=======================
Run a repeat‑able benchmark of the five motion–planning
algorithms defined in *motion_planning.py* and store one CSV
row per planner (per run).

Metrics collected per planner
-----------------------------
* **success_rate%** – percentage of start/goal pairs solved.
* **plan_time_s**   – average wall‑clock time taken by the solver.
* **exec_time_s**   – average real‑time duration of the produced path.
* **smoothness**    – summed squared curvature; 0 == perfectly straight.
* **clearance_m**   – minimum robot–obstacle separation along the path.
* **mem_MB**        – mean additional resident memory used while planning.

Only the actual call to the *planner function* is timed, so the
benchmark is agnostic to simulation start‑up, IK, logging, etc.
"""
from __future__ import annotations

import os
import csv
import json
import time
from datetime import datetime
from pathlib import Path

import numpy as np
import pybullet as p
import pybullet_data

# -- optional dependency ----------------------------------------------
try:
    # psutil allows us to measure per‑process resident set size (RSS)
    import psutil
    _PROC = psutil.Process(os.getpid())
except ImportError:  # pragma: no cover – psutil not installed
    psutil = None
    _PROC = None  # fall‑back when memory metric is unavailable

# -- project‑specific imports -----------------------------------------
from utils.motion_planning import (
    plan_motion_rrt,
    plan_motion_lazy_prm,
    plan_motion_prm,
    plan_motion_rrt_connect,
    plan_motion_straight,
    execute_motion_plan,
    get_movable_joints,
)
from utils.simEnv import SimEnv
from utils.panda_sim_grasp_arm import PandaSim

# ---------------------------------------------------------------------
PAIRS_JSON: str = "benchmark_pairs.json"  # generated by motion_test.py
RESULTS_CSV: str = "benchmark_results.csv"

DT: float = 1 / 240.0   # PyBullet real‑time step (sec)
VISUALISE: bool = True  # GUI toggle – set True to watch the robot

# Map planner names to the callable wrappers in motion_planning.py
PLANNERS: dict[str, callable] = {
    "rrt": plan_motion_rrt,
    "lazy_prm": plan_motion_lazy_prm,
    "prm": plan_motion_prm,
    "rrt_connect": plan_motion_rrt_connect,
    "straight": plan_motion_straight,
}

# --------------------------------------------------------------------
# Helper functions – metrics
# --------------------------------------------------------------------

def _path_smoothness(path: list[list[float]]) -> float:
    """Return a *qualitative* smoothness number for a joint‑space path.

    The metric is the sum of Euclidean norms of the discrete second
    derivative: ‖qᵢ₊₁ − 2 qᵢ + qᵢ₋₁‖.  A perfectly straight path has a
    smoothness of *0*; a highly zig‑zagging path yields a large number.
    The absolute scale is not important – only relative comparisons
    between planners for the *same* robot are meaningful.
    """
    if len(path) < 3:
        return 0.0  # nothing to differentiate
    arr = np.asarray(path)
    second = arr[2:] - 2 * arr[1:-1] + arr[:-2]
    return float(np.sum(np.linalg.norm(second, axis=1)))


def _path_clearance(
    robot_id: int,
    joints: list[int],
    obstacles: list[int],
    path: list[list[float]],
    threshold: float = 1.0,
) -> float:
    """Return the *minimum* robot–obstacle distance (metres).

    For every configuration on *path* the robot joints are temporarily
    teleported (``resetJointState``) and PyBullet’s *getClosestPoints*
    is queried against each obstacle.  The smallest distance across the
    entire trajectory is returned.  If *path* is empty, *nan* is
    returned so it will be ignored by ``np.nanmean``.
    """
    if not path:
        return float("nan")

    min_dist = float("inf")
    for conf in path:
        # --- set robot pose without integration ----------------------
        for j, v in zip(joints, conf):
            p.resetJointState(robot_id, j, float(v))

        # --- query distance to every obstacle ------------------------
        for obs in obstacles:
            # element [8] is separation distance (negative → penetration)
            pts = p.getClosestPoints(robot_id, obs, threshold)
            if pts:
                local_min = min(pt[8] for pt in pts)
                if local_min < min_dist:
                    min_dist = local_min

    return float(min_dist) if min_dist != float("inf") else float("nan")


# --------------------------------------------------------------------
# Core benchmarking routine
# --------------------------------------------------------------------

def load_pairs(fname: str) -> tuple[list, list]:
    """Parse the JSON file produced by *motion_test.py* and return two
    lists: *start* and *goal* joint configurations.
    """
    with Path(fname).open() as fp:
        data = json.load(fp)
    return data["start"], data["goal"]


def bench_single(
    planner_name: str,
    planner_fun: callable,
    robot_id: int,
    joints: list[int],
    obstacles: list[int],
    start_list: list[list[float]],
    goal_list: list[list[float]],
) -> dict[str, float]:
    """Run *one* planner over *all* start/goal pairs and collect stats.

    Returns
    -------
    dict
        Keys correspond 1‑to‑1 with the CSV columns (without timestamp
        and planner name, which are added by the caller).
    """

    # Per‑case arrays – kept separate to allow np.nanmean later
    plan_times, exec_times = [], []
    smooth_vals, clear_vals, mem_deltas = [], [], []
    successes = 0

    for qs, qg in zip(start_list, goal_list):
        # ----- memory before planning --------------------------------
        mem_before = _PROC.memory_info().rss if _PROC else 0

        # ----- planning time -----------------------------------------
        t0 = time.perf_counter()
        path = planner_fun(robot_id, joints, qs, qg, obstacles)
        t1 = time.perf_counter()
        plan_times.append(t1 - t0)

        # ----- memory delta ------------------------------------------
        mem_after = _PROC.memory_info().rss if _PROC else mem_before
        mem_deltas.append((mem_after - mem_before) / (1024 ** 2))  # → MB

        if path:  # planner succeeded
            successes += 1

            # execution time = path length × real-time step
            exec_times.append(len(path) * DT)

            # geometric metrics
            smooth_vals.append(_path_smoothness(path))
            clear_vals.append(_path_clearance(robot_id, joints, obstacles, path))

            if VISUALISE:
                # Play back in the GUI (optional, no timing impact)
                execute_motion_plan(robot_id, joints, path, sleep_time=0)
        else:
            # Maintain list lengths for np.nanmean()
            exec_times.append(np.nan)
            smooth_vals.append(np.nan)
            clear_vals.append(np.nan)

    # ---- aggregate over all pairs ----------------------------------
    succ_rate = 100 * successes / len(start_list)

    return {
        "cases": len(start_list),
        "success_rate%": round(succ_rate, 1),
        "plan_time_s": round(float(np.nanmean(plan_times)), 4),
        "exec_time_s": round(float(np.nanmean(exec_times)), 4),
        "smoothness": round(float(np.nanmean(smooth_vals)), 4),
        "clearance_m": round(float(np.nanmean(clear_vals)), 4)
        if not np.isnan(np.nanmean(clear_vals)) else np.nan,
        "mem_MB": round(float(np.nanmean(mem_deltas)), 3),
    }


# --------------------------------------------------------------------
# Script entry point
# --------------------------------------------------------------------

def main() -> None:
    """Entry point: connect to PyBullet, run benchmarks, append CSV."""

    # 0) load the fixed set of benchmark queries ---------------------
    if not os.path.exists(PAIRS_JSON):
        raise FileNotFoundError(
            f"{PAIRS_JSON} not found. Run motion_test.py --regen first.")
    start_confs, goal_confs = load_pairs(PAIRS_JSON)

    # 1) connect to physics engine (GUI optional) --------------------
    connection = p.GUI if VISUALISE else p.DIRECT
    p.connect(connection)
    p.setAdditionalSearchPath(pybullet_data.getDataPath())
    p.setGravity(0, 0, -10)

    # 2) spawn world & robot ----------------------------------------
    panda = PandaSim(p, [0, -0.6, 0])  # position matches motion_test
    env = SimEnv(p, path="", gripperId=panda.pandaId)
    obstacles = env.shelf_ids + [env.planeId]
    joints = get_movable_joints(panda.pandaId)

    # 3) run benchmarks ---------------------------------------------
    rows = []
    for name, fun in PLANNERS.items():
        print(f"\n### {name.upper()} ########################################")
        metrics = bench_single(
            name,
            fun,
            panda.pandaId,
            joints,
            obstacles,
            start_confs,
            goal_confs,
        )

        rows.append({
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "planner": name,
            **metrics,
        })

    # 4) append (or create) CSV file -------------------------------
    new_file = not os.path.exists(RESULTS_CSV)
    with Path(RESULTS_CSV).open("a", newline="") as fp:
        writer = csv.DictWriter(fp, fieldnames=rows[0].keys())
        if new_file:
            writer.writeheader()
        writer.writerows(rows)
    print(f"\n✓ Results appended to {RESULTS_CSV}")

    # 5) clean up ---------------------------------------------------
    p.disconnect()


# --------------------------------------------------------------------
if __name__ == "__main__":
    main()
